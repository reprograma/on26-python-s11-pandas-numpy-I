{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glassdoor Data Science Job Listings\n",
    "This dataset comprises information extracted from 1,500 job postings related to data science from Glassdoor.com. The data encompasses essential details about each job listing, facilitating comprehensive analysis and insights into the data science job market.\n",
    "link: https://www.kaggle.com/datasets/rrkcoder/glassdoor-data-science-job-listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import csv file\n",
    "\n",
    "df = pd.read_csv(\"glassdoor_data_jobs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {df.shape[0]} rows and {df.shape[1]} columns in this dataset.\")\n",
    "print(f\"The name of the columns are:\\n{df.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for duplicates\n",
    "print(f\"There are {df.duplicated().sum()} duplicated rows in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for null data\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a copy to clean and manipulate the data without changing the original dataset \n",
    "\n",
    "def processing_data(df):\n",
    "\n",
    "    # Deleting duplicates\n",
    "    df.drop_duplicates(inplace = True)\n",
    "\n",
    "    # Deleting column Job Description\n",
    "    df.drop(columns=['Job Description'], inplace=True)\n",
    "\n",
    "    # Eliminating Rating and salary lower than 0\n",
    "    df.loc[df[\"Rating\"] == -1, \"Rating\"] = None\n",
    "    df.loc[df[\"Salary Estimate\"] == \"-1\", \"Salary Estimate\"] = None\n",
    "    df.loc[df[\"Industry\"] == \"-1\", \"Industry\"] = None\n",
    "    df.loc[df[\"Sector\"] == \"-1\", \"Sector\"] = None\n",
    "    df.loc[df[\"Founded\"] == \"-1\", \"Founded\"] = None\n",
    "\n",
    "    # Eliminating company size lower than 0 or unknown\n",
    "    df.loc[df[\"Size\"] == \"-1\", \"Size\"] = None\n",
    "    df.loc[df[\"Size\"] == \"Unknown\", \"Size\"] = None\n",
    "\n",
    "    #Converting years to int\n",
    "    df[\"Founded\"] = df[\"Founded\"].astype(int)\n",
    "\n",
    "    # Eliminating null\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    # Sorting by rating in descending order\n",
    "    df.sort_values(by = \"Rating\", ascending = False, inplace = True)\n",
    "\n",
    "df_processed = df.copy()\n",
    "processing_data(df_processed)\n",
    "df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting helped identifying overlying data to be cleaned up.\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(data=df_processed, x=\"Rating\", bins=20, kde=True)\n",
    "plt.title(\"Distribution of Company Ratings\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting helped identifying overlying data to be cleaned up.\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(data=df_processed, x='Size')\n",
    "plt.title('Company Size Distribution')\n",
    "plt.xlabel('Company Size')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Várias informações podem ser extraídas do dataset, porém, exige uma melhor limpeza, organização e padronização dos dados. \n",
    "No momento, podemos observar que existe uma concentração muito grande de empresas com rating entre 3.5 e 4.5. \n",
    "Também observamos que a grande maioria das empresas que oferecem vagas de ciência de dados tem mais de 10000 integrantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data_jobs_cleaned.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
